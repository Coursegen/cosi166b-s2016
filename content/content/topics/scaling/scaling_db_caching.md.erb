---
title: Scaling by Database Caching
---

### Scalability Pattern: Database Caching

#### Example, Social Graph
* Classic Relational Approach
  * Schema (like all of you have)
    * People(id, name)
    * Follow(id, follower_id, following_id)
    * Content(id, author_id)
  * Nicely normalized
    * First, Second and Third Normal form
    * Origins of the relational database
  * Queries like:
    * How many people are following user X?
    * Who is following user Y?
    * What are the most recent "n" posts (i.e. content) for user "u"?
    * What are the most recent "n" posts for users that "u" is following?
  * But to display each and every user, a join is needed!

#### Measurement
* Ask database system to analyze SQL queries that are slow
  * e.g. `heroku pg:outliers`
  * Discover that the social graph access was very slow
* Solution: Caching
  * Use Network scale caching (Redis) to store and share across servers

#### Caching with "Redis"
* Analogous to other network scale caching solutions (e.g. cached)
* Typical structure is a key-value store
* A nosql database. But in memory
* It has some interesting characteristics
  * ATOMIC operations, e.g. "INCR" operation
  * keys that expire (TTL)
  * Supports other values: lists, sets, hashes
  * And many many more
* [Play with Redis](http://try.redis.io)
* Ruby bindings [`gem redis-objects`](https://github.com/nateware/redis-objects)
* Wait, where's the data actually stored?
  * A redis host, accessible by tcp/ip: dns name + port number
  * You can run it
  * Heroku can run it for you with [Redis to go](https://devcenter.heroku.com/articles/redistogo). Nano size is free!
  * In all cases, if the host dies, the data is gone

#### Putting the it together
* Example:
  * Display list of 50 most recent posts for users who are followed by user u
  * Key is: 50_tweets_for_user:uid
  * Value is: ordered list of tweet ids
* Processing:
  * When list is displayed
  * When user :u tweets
